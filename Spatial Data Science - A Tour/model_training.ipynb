{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using the ArcGIS API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating training sample data, you typically have to prepare this data by splitting it into training and validation sets, applying data augmentation techniques, and creating batches for computer memory management. The ArcGIS API `prepare_data` method can automate this entire process. It uses a default set of transformations to augment the training sample data. You can specify your own transformations or keep the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages.\n",
    "from arcgis.learn import SingleShotDetector, prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image chips into memory.\n",
    "data_path = r'Enter the path to the image chips'\n",
    "data_path = r\"C:\\Users\\albe9057\\Documents\\3_Presentations\\20200211_FedGIS_2_MLinArcGIS\\ObjectDetection\\ImageChips\"\n",
    "\n",
    "#Run the prepare_data method, specifying the class value and name but leaving the default transformations.\n",
    "data = prepare_data(data_path, {0:'Pool'})\n",
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastai.vision.data import imagenet_stats, ImageList, bb_pad_collate\n",
    "from fastai.vision.transform import crop, rotate, dihedral_affine, brightness, contrast, skew, rand_zoom, get_transforms, flip_lr\n",
    "from fastai.vision import ImageDataBunch\n",
    "from fastai.torch_core import data_collate\n",
    "import torch\n",
    "from .models._ssd_utils import SSDObjectItemList\n",
    "from .models._unet_utils import ArcGISSegmentationItemList, ArcGISSegmentationMSItemList, _show_batch_unet_multispectral\n",
    "from .models._maskrcnn_utils import ArcGISInstanceSegmentationItemList\n",
    "from .models._ner_utils import ner_prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the augmented training sample data\n",
    "The`.show_batch()` method will visualize the exported training samples and their labels after applying the data augmentation transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a random sample of image chips.\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the deep learning model architecture\n",
    "`arcgis.learn` includes deep learning models that use pretrained Convolutional Neural Networks (CNNs). You will use the Single-Shot Detector (SSD). SSD is one of the most advanced object detection algorithms and is based on a pretrained CNN. A SSD model architecture has been predefined in `arcgis.learn`. For more information about SSD and its integration into `arcigs.learn,` see ArcGIS API for Python Help: [How single-shot detector (SSD) works?](https://developers.arcgis.com/python/guide/how-ssd-works/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the Single-Shot Detector model\n",
    "ssd = SingleShotDetector(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find an optimal learning rate\n",
    "The learning rate controls the weighting adjustment of the neural network. A low learning rate trains the model slowly, while a high learning rate can jump to conclusions and learn the incorrect information. The ArcGIS Python API provides a learning rate finder that finds a rate which loss, or model error, is lowest before it starts to increase again, indicating that the learning rate is too high and introducing error into the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the learning rate plot above, the loss drops dramatically at 1e-2, so you will use this rate for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd.fit(25, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the model\n",
    "Comparing the ground truth images with the predicted images will help you determine the accuracy of your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ssd.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model provides a good baseline, predicting most of the pools identified in the ground truth. You could modify the parameters of this tool (number of epochs, grid cell size, and so on) to improve the results of the model. Because these modifications would require more processing time, we will proceed with this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd.save('PoolsModel_25_SSD_Script') # save it to your local directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "687px",
    "left": "427px",
    "top": "210px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
